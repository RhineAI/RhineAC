{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T04:21:23.606635600Z",
     "start_time": "2024-12-18T04:21:23.565602600Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcb1eccd52d1428ba5b53107d31e8c26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-35): 36 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
      ")\n",
      "Qwen2TokenizerFast(name_or_path='/data/disk1/guohaoran/model/self/Qwen2.5-3B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/data/disk1/guohaoran/model/self/Qwen2.5-3B-Instruct\"\n",
    "device = 'cuda:7'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float64,\n",
    "    device_map=device,\n",
    ")\n",
    "print(model)\n",
    "print(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T04:21:28.629883500Z",
     "start_time": "2024-12-18T04:21:23.606635600Z"
    }
   },
   "id": "88057f7fb9a794b8"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask', 'id', 'length'],\n",
      "        num_rows: 34701\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask', 'id', 'length'],\n",
      "        num_rows: 3856\n",
      "    })\n",
      "})\n",
      "{'text': '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nhtml로 나의 첫번째 웹페어지를 만들어줘<|im_end|>\\n<|im_start|>assistant\\n当然！请按照以下方式编写代码。\\n```php\\n<!DOCTYPE html>\\n<html>\\n<head>\\n\\t<title>我的第一个网页</title>\\n</head>\\n<body>\\n\\t<h1>您好！</h1>\\n\\t<p>这是我的第一个网页。</p>\\n\\t<img src=\"https://via.placeholder.com/150\" alt=\"替代文本\">\\n</body>\\n</html>\\n```\\n此代码通过使用`<!DOCTYPE html>`声明HTML5文档，使用`<html>`标签标记HTML文档的开始，使用`<head>`标签声明文档标题的`<title>`标签。在`<body>`标签中，网页的内容被放置。`<h1>`标签表示标题，`<p>`标签表示正文。最后，`<img>`标签插入图片。图像通过`src`属性插入图像URL，通过`alt`属性放入备用文本，以避免当图像无法加载时使用默认备用文本。<|im_end|>\\n<|im_start|>user\\n请解释一下代码。<|im_end|>\\n<|im_start|>assistant\\n我会简单地介绍一下代码。\\n```php\\n<!DOCTYPE html>\\n```\\n* 这句话说明这是HTML5文档。\\n```css\\n<html>\\n```\\n* `<html>`标签表示HTML文档的开始，它包含了HTML文档的所有内容。\\n```php\\n<head>\\n\\t<title>我的第一个网页</title>\\n</head>\\n```\\n* `<head>`标签定义HTML文档的元数据。在这里，我们使用`<title>`标签表示文档的标题。\\n```php\\n<body>\\n\\t<h1>你好!</h1>\\n\\t<p>这是我的第一个网页。</p>\\n\\t<img src=\"https://via.placeholder.com/150\" alt=\"替代文本\">\\n</body>\\n```\\n* `<body>`标签定义HTML文档的正文。它包含了网页的所有内容。在这里，我们使用`<h1>`标签表示标题，使用`<p>`标签表示正文。最后，使用`<img>`标签插入图像。\\n```css\\n<img src=\"https://via.placeholder.com/150\" alt=\"替代文本\">\\n```\\n* `<img>`标签是插入图像的标签。在`src`属性中输入图像的URL，在`alt`属性中输入替代文本。这样的替代文本在一些用户，比如视觉障碍的用户在使用网站时显得非常重要。<|im_end|>\\n<|im_start|>user\\n| 出差费用清单 | 金额 |\\n| 交通费 | 45000 |\\n| 总金额 | 103000 |\\n告诉我有误的地方。<|im_end|>\\n<|im_start|>assistant\\n以上代码存在一些问题。修改如下：\\n```css\\n<table>\\n    <thead>\\n        <tr>\\n            <th>差旅费详细</th>\\n            <th>金额</th>\\n        </tr>\\n    </thead>\\n    <tbody>\\n        <tr>\\n            <td>交通费</td>\\n            <td>45,000</td>\\n        </tr>\\n    </tbody>\\n    <tfoot>\\n        <tr>\\n            <td>总计</td>\\n            <td>103,000</td>\\n        </tr>\\n    </tfoot>\\n</table>\\n```\\n* 请使用 `<thead>` 而不是 `<thaed>`。\\n* 缺少了闭合 `<tbody>` 标签，因此加上 `</tbody>`。\\n* 在表示金额时，使用千位分隔符增加可读性。\\n* `</thead>` 标签缺少在 `</tbody>` 标签之前，因此添加 `</thead>`。\\n* `<tfoot>` 标签应位于表格底部，因此应在最后位置。<|im_end|>\\n', 'input_ids': [[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 1551, 17380, 73518, 20401, 48364, 104, 137104, 85413, 117, 135807, 31079, 133120, 134108, 144131, 151645, 198, 151644, 77091, 198, 103942, 6313, 14880, 101892, 87752, 75768, 108598, 46100, 8997, 73594, 1208, 198, 13543, 15458, 5272, 397, 13745, 397, 16343, 397, 197, 27336, 29, 97611, 102344, 106384, 522, 2102, 397, 522, 1983, 397, 15527, 397, 197, 9969, 16, 29, 111308, 6313, 522, 71, 16, 397, 197, 7926, 29, 100346, 97611, 102344, 106384, 37132, 79, 397, 197, 20092, 2286, 428, 2428, 1110, 20105, 31531, 905, 14, 16, 20, 15, 1, 4797, 428, 105598, 108704, 881, 522, 2599, 397, 522, 1551, 397, 13874, 3989, 31991, 46100, 67338, 37029, 63, 13543, 15458, 5272, 43626, 82641, 5835, 20, 111116, 3837, 37029, 63, 27, 1551, 43626, 105151, 113743, 5835, 111116, 9370, 55286, 3837, 37029, 63, 27, 1983, 43626, 105151, 82641, 111116, 60396, 9370, 63, 27, 2102, 43626, 105151, 1773, 18493, 63, 27, 2599, 43626, 105151, 15946, 3837, 106384, 104597, 99250, 107826, 1773, 63, 27, 71, 16, 43626, 105151, 51463, 60396, 3837, 63, 27, 79, 43626, 105151, 51463, 110644, 1773, 100161, 3837, 63, 27, 1892, 43626, 105151, 114731, 45930, 1773, 107553, 67338, 63, 3548, 63, 79256, 114731, 107553, 3144, 3837, 67338, 63, 3145, 63, 79256, 105851, 109063, 108704, 3837, 23031, 101153, 39165, 107553, 101068, 58814, 13343, 37029, 47363, 109063, 108704, 1773, 151645, 198, 151644, 872, 198, 14880, 104136, 100158, 46100, 1773, 151645, 198, 151644, 77091, 198, 105351, 100405, 29490, 109432, 46100, 8997, 73594, 1208, 198, 13543, 15458, 5272, 397, 13874, 3989, 9, 32181, 247, 100908, 66394, 100346, 5835, 20, 111116, 8997, 73594, 5143, 198, 13745, 397, 13874, 3989, 9, 30586, 1551, 43626, 105151, 51463, 5835, 111116, 9370, 55286, 3837, 99652, 115191, 5835, 111116, 105679, 43815, 8997, 73594, 1208, 198, 16343, 397, 197, 27336, 29, 97611, 102344, 106384, 522, 2102, 397, 522, 1983, 397, 13874, 3989, 9, 30586, 1983, 43626, 105151, 91282, 5835, 111116, 9370, 23305, 20074, 1773, 104067, 3837, 97639, 37029, 63, 27, 2102, 43626, 105151, 51463, 111116, 9370, 60396, 8997, 73594, 1208, 198, 15527, 397, 197, 9969, 16, 29, 108386, 18685, 71, 16, 397, 197, 7926, 29, 100346, 97611, 102344, 106384, 37132, 79, 397, 197, 20092, 2286, 428, 2428, 1110, 20105, 31531, 905, 14, 16, 20, 15, 1, 4797, 428, 105598, 108704, 881, 522, 2599, 397, 13874, 3989, 9, 30586, 2599, 43626, 105151, 91282, 5835, 111116, 9370, 110644, 1773, 99652, 115191, 106384, 105679, 43815, 1773, 104067, 3837, 97639, 37029, 63, 27, 71, 16, 43626, 105151, 51463, 60396, 3837, 37029, 63, 27, 79, 43626, 105151, 51463, 110644, 1773, 100161, 3837, 37029, 63, 27, 1892, 43626, 105151, 114731, 107553, 8997, 73594, 5143, 198, 20092, 2286, 428, 2428, 1110, 20105, 31531, 905, 14, 16, 20, 15, 1, 4797, 428, 105598, 108704, 881, 13874, 3989, 9, 30586, 1892, 43626, 105151, 20412, 114731, 107553, 9370, 105151, 1773, 18493, 63, 3548, 63, 79256, 15946, 31196, 107553, 9370, 3144, 96050, 63, 3145, 63, 79256, 15946, 31196, 105598, 108704, 1773, 101893, 105598, 108704, 18493, 101883, 20002, 3837, 101912, 104916, 102544, 9370, 20002, 18493, 37029, 100010, 13343, 104392, 106078, 1773, 151645, 198, 151644, 872, 198, 91, 65727, 118, 99572, 103966, 105713, 760, 220, 80094, 9248, 91, 220, 99735, 80268, 760, 220, 19, 20, 15, 15, 15, 9248, 91, 90476, 119, 80094, 760, 220, 16, 15, 18, 15, 15, 15, 9248, 106525, 18830, 29056, 103958, 1773, 151645, 198, 151644, 77091, 198, 70589, 46100, 47606, 101883, 86119, 1773, 25177, 104506, 28311, 73594, 5143, 198, 20993, 397, 262, 366, 11417, 397, 286, 366, 376, 397, 310, 366, 339, 29, 99572, 99407, 80268, 100700, 522, 339, 397, 310, 366, 339, 29, 80094, 522, 339, 397, 286, 690, 376, 397, 262, 690, 11417, 397, 262, 366, 10095, 397, 286, 366, 376, 397, 310, 366, 1296, 29, 99735, 80268, 522, 1296, 397, 310, 366, 1296, 29, 19, 20, 11, 15, 15, 15, 522, 1296, 397, 286, 690, 376, 397, 262, 690, 10095, 397, 262, 366, 58484, 397, 286, 366, 376, 397, 310, 366, 1296, 29, 114256, 522, 1296, 397, 310, 366, 1296, 29, 16, 15, 18, 11, 15, 15, 15, 522, 1296, 397, 286, 690, 376, 397, 262, 690, 58484, 397, 522, 2005, 397, 13874, 3989, 9, 220, 14880, 37029, 30586, 11417, 43626, 8908, 222, 234, 99520, 30586, 22410, 291, 43626, 8997, 9, 84238, 118, 108373, 58792, 39762, 30586, 10095, 43626, 51461, 229, 61755, 3837, 101886, 102189, 1565, 522, 10095, 43626, 8997, 9, 73562, 51463, 80094, 13343, 3837, 37029, 99320, 24156, 17177, 99859, 38304, 100649, 30440, 57553, 33071, 8997, 9, 1565, 522, 11417, 43626, 51461, 229, 61755, 102822, 18493, 1565, 522, 10095, 43626, 51461, 229, 61755, 101056, 3837, 101886, 42855, 1565, 522, 11417, 43626, 8997, 9, 30586, 58484, 43626, 51461, 229, 61755, 50511, 103987, 112611, 108304, 3837, 101886, 110391, 100161, 81812, 1773, 151645, 198, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'id': 'XM1wgEc', 'length': 1893}\n"
     ]
    }
   ],
   "source": [
    "tag_map = {\n",
    "    'human': 'user',\n",
    "    'gpt': 'assistant',\n",
    "    'system': 'system',\n",
    "    'function_call': 'function',\n",
    "    'observation': 'observation',\n",
    "}\n",
    "\n",
    "def process(row):\n",
    "    data = json.loads(row['text'])\n",
    "    messages = [{'role': tag_map[line['from']], 'content': line['value']} for line in data['conversations']]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    result = tokenizer([text], return_tensors=\"np\", padding='max_length', max_length=1024, truncation=True)\n",
    "    result.update({'id': data['id'], 'text': text, 'length': len(text)})\n",
    "    return result\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path='text',\n",
    "    data_files=['/data/disk1/guohaoran/data/sharegpt_zh_38K.jsonl'],\n",
    "    cache_dir='/data/disk1/guohaoran/data/.cache',\n",
    "    split='train',\n",
    ")\n",
    "dataset = dataset.map(process)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "train_dataset = train_dataset.shuffle()\n",
    "\n",
    "print(dataset)\n",
    "item = train_dataset[0]\n",
    "print(item)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T04:21:29.644296800Z",
     "start_time": "2024-12-18T04:21:28.631876500Z"
    }
   },
   "id": "6c5b664022d19fbd"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.DoubleTensor{[2, 2, 1, 1, 1024]}, size=[2, 1, 1, 1024]): the number of sizes provided (4) must be greater or equal to the number of dimensions in the tensor (5)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 13\u001B[0m\n\u001B[1;32m      1\u001B[0m training_args \u001B[38;5;241m=\u001B[39m Seq2SeqTrainingArguments(\n\u001B[1;32m      2\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/data/disk1/guohaoran/RhineAC/workspace/output\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      3\u001B[0m     eval_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     per_device_train_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      5\u001B[0m     per_gpu_train_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      6\u001B[0m )\n\u001B[1;32m      7\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Seq2SeqTrainer(\n\u001B[1;32m      8\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      9\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m     10\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtrain_dataset,\n\u001B[1;32m     11\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mtest_dataset,\n\u001B[1;32m     12\u001B[0m )\n\u001B[0;32m---> 13\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:1938\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1936\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1937\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1938\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   1939\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   1940\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[1;32m   1941\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[1;32m   1942\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[1;32m   1943\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2279\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2276\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   2278\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 2279\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   2281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2282\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2283\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2284\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2285\u001B[0m ):\n\u001B[1;32m   2286\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2287\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3318\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   3315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3317\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3318\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(model, inputs)\n\u001B[1;32m   3320\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m inputs\n\u001B[1;32m   3321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   3322\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3323\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   3324\u001B[0m ):\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3363\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   3361\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3362\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3363\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[1;32m   3364\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3365\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3366\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:1104\u001B[0m, in \u001B[0;36mQwen2ForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1101\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1104\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[1;32m   1105\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1106\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   1107\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   1108\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m   1109\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m   1110\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m   1111\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1112\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m   1113\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1114\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m   1115\u001B[0m )\n\u001B[1;32m   1117\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1118\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(hidden_states)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:888\u001B[0m, in \u001B[0;36mQwen2Model.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    885\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m position_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    886\u001B[0m     position_ids \u001B[38;5;241m=\u001B[39m cache_position\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 888\u001B[0m causal_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_causal_mask(\n\u001B[1;32m    889\u001B[0m     attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n\u001B[1;32m    890\u001B[0m )\n\u001B[1;32m    892\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m inputs_embeds\n\u001B[1;32m    894\u001B[0m \u001B[38;5;66;03m# decoder layers\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:1000\u001B[0m, in \u001B[0;36mQwen2Model._update_causal_mask\u001B[0;34m(self, attention_mask, input_tensor, cache_position, past_key_values, output_attentions)\u001B[0m\n\u001B[1;32m    993\u001B[0m     target_length \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    994\u001B[0m         attention_mask\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    995\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(attention_mask, torch\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m    996\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m past_seen_tokens \u001B[38;5;241m+\u001B[39m sequence_length \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    997\u001B[0m     )\n\u001B[1;32m    999\u001B[0m \u001B[38;5;66;03m# In case the provided `attention` mask is 2D, we generate a causal mask here (4D).\u001B[39;00m\n\u001B[0;32m-> 1000\u001B[0m causal_mask \u001B[38;5;241m=\u001B[39m _prepare_4d_causal_attention_mask_with_cache_position(\n\u001B[1;32m   1001\u001B[0m     attention_mask,\n\u001B[1;32m   1002\u001B[0m     sequence_length\u001B[38;5;241m=\u001B[39msequence_length,\n\u001B[1;32m   1003\u001B[0m     target_length\u001B[38;5;241m=\u001B[39mtarget_length,\n\u001B[1;32m   1004\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1005\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m   1006\u001B[0m     min_dtype\u001B[38;5;241m=\u001B[39mmin_dtype,\n\u001B[1;32m   1007\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m   1008\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39minput_tensor\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   1009\u001B[0m )\n\u001B[1;32m   1011\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1012\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_attn_implementation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msdpa\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1013\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1018\u001B[0m     \u001B[38;5;66;03m# using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\u001B[39;00m\n\u001B[1;32m   1019\u001B[0m     \u001B[38;5;66;03m# Details: https://github.com/pytorch/pytorch/issues/110213\u001B[39;00m\n\u001B[1;32m   1020\u001B[0m     causal_mask \u001B[38;5;241m=\u001B[39m AttentionMaskConverter\u001B[38;5;241m.\u001B[39m_unmask_unattended(causal_mask, min_dtype)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:109\u001B[0m, in \u001B[0;36m_prepare_4d_causal_attention_mask_with_cache_position\u001B[0;34m(attention_mask, sequence_length, target_length, dtype, device, min_dtype, cache_position, batch_size)\u001B[0m\n\u001B[1;32m    107\u001B[0m         padding_mask \u001B[38;5;241m=\u001B[39m causal_mask[:, :, :, :mask_length] \u001B[38;5;241m+\u001B[39m attention_mask[:, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, :]\n\u001B[1;32m    108\u001B[0m         padding_mask \u001B[38;5;241m=\u001B[39m padding_mask \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 109\u001B[0m         causal_mask[:, :, :, :mask_length] \u001B[38;5;241m=\u001B[39m causal_mask[:, :, :, :mask_length]\u001B[38;5;241m.\u001B[39mmasked_fill(\n\u001B[1;32m    110\u001B[0m             padding_mask, min_dtype\n\u001B[1;32m    111\u001B[0m         )\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m causal_mask\n",
      "\u001B[0;31mRuntimeError\u001B[0m: expand(torch.cuda.DoubleTensor{[2, 2, 1, 1, 1024]}, size=[2, 1, 1, 1024]): the number of sizes provided (4) must be greater or equal to the number of dimensions in the tensor (5)"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='/data/disk1/guohaoran/RhineAC/workspace/output',\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_gpu_train_batch_size=2,\n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T04:21:31.280378500Z",
     "start_time": "2024-12-18T04:21:29.644296800Z"
    }
   },
   "id": "33d4c30fa86b1710"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-18T04:21:31.280378500Z"
    }
   },
   "id": "8d45a621798a6bc8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
